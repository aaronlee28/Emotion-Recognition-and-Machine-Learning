{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357e1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# if it is the first time using nltk uncomment line below and run it and download it\n",
    "# nltk.download()\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e71b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import csv training dataset. Please refer to the readme; due to size this was not included in the repository.\n",
    "df = pd.read_csv('Sentiment_Analysis_Dataset.csv', error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335eea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my APL frie...\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          1                            omg its already 7:30 :O\n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns to use\n",
    "df_cleaned = df[['Sentiment', 'SentimentText']]\n",
    "df_cleaned = df_cleaned[pd.notnull(df_cleaned['SentimentText'])]\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662a3d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1578612, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shape of dataset\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b21ccfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    790177\n",
       "0    788435\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative is represented by the number 0 and Positive by 1\n",
    "df_cleaned.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97359cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index due to some skipping rows (error) while loading csv\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32ef916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(df):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import nltk\n",
    "    # nltk.download()\n",
    "    from nltk import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    \n",
    "    df['cleaned_text'] = \"\"\n",
    "    df['tokenized'] = \"\"\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text = row['SentimentText'].lower()\n",
    "        cleaned = [char for char in text if char not in string.punctuation]\n",
    "        cleaned = \"\".join(cleaned)\n",
    "        tokenized = word_tokenize(cleaned)\n",
    "        df.at[index, 'cleaned_text'] = cleaned\n",
    "        df.at[index, 'tokenized'] = tokenized\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d3fae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pred_cleaning(data, tfidf_vect, model):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import nltk\n",
    "    # nltk.download()\n",
    "    from nltk import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "\n",
    "    text = data.lower()\n",
    "    cleaned = [char for char in text if char not in string.punctuation]\n",
    "    cleaned = \"\".join(cleaned)\n",
    "    result = np.array([cleaned])\n",
    "    \n",
    "    result_prediction = text_pred_features(result, tfidf_vect, model)\n",
    "    \n",
    "    \n",
    "    return result_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec41731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(df, test_size):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import pickle\n",
    "\n",
    "    X = df['cleaned_text']\n",
    "    y = df['Sentiment']\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    \n",
    "    tfidf_vect.fit(X_train)\n",
    "    \n",
    "    cls = MultinomialNB()\n",
    "    \n",
    "    cls.fit(tfidf_vect.transform(X_train), y_train)\n",
    "    \n",
    "    # Saving Model\n",
    "    filename = \"text_emotions_model.sav\"\n",
    "    pickle.dump(cls, open(filename, 'wb'))\n",
    "    \n",
    "    # Saving Verctorizer\n",
    "    with open('tfidf_vect.pk', 'wb') as fin:\n",
    "        pickle.dump(tfidf_vect, fin)\n",
    "    \n",
    "    return cls, tfidf_vect, X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3d110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pred_features(text, tfidf_vect, model):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    text_vect = tfidf_vect.transform(text).toarray()\n",
    "    \n",
    "    emotion = model.predict(text_vect.reshape(1, -1))[0]\n",
    "    \n",
    "    emotions = {0:'Negative',\n",
    "                1:'Positive'}\n",
    "    \n",
    "    result = emotions[emotion]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123617ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>is so sad for my apl friend</td>\n",
       "      <td>[is, so, sad, for, my, apl, friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>i missed the new moon trailer</td>\n",
       "      <td>[i, missed, the, new, moon, trailer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg its already 730 o</td>\n",
       "      <td>[omg, its, already, 730, o]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga im sooo  im gunna cry ive be...</td>\n",
       "      <td>[omgaga, im, sooo, im, gunna, cry, ive, been, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>i think mi bf is cheating on me       tt</td>\n",
       "      <td>[i, think, mi, bf, is, cheating, on, me, tt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "      <td>or i just worry too much</td>\n",
       "      <td>[or, i, just, worry, too, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "      <td>juuuuuuuuuuuuuuuuussssst chillin</td>\n",
       "      <td>[juuuuuuuuuuuuuuuuussssst, chillin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n",
       "      <td>sunny again        work tomorrow       ...</td>\n",
       "      <td>[sunny, again, work, tomorrow, tv, tonight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "      <td>handed in my uniform today  i miss you a...</td>\n",
       "      <td>[handed, in, my, uniform, today, i, miss, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "      <td>hmmmm i wonder how she my number</td>\n",
       "      <td>[hmmmm, i, wonder, how, she, my, number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>I must think about positive..</td>\n",
       "      <td>i must think about positive</td>\n",
       "      <td>[i, must, think, about, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>thanks to all the haters up in my face a...</td>\n",
       "      <td>thanks to all the haters up in my face a...</td>\n",
       "      <td>[thanks, to, all, the, haters, up, in, my, fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>this weekend has sucked so far</td>\n",
       "      <td>this weekend has sucked so far</td>\n",
       "      <td>[this, weekend, has, sucked, so, far]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>jb isnt showing in australia any more!</td>\n",
       "      <td>jb isnt showing in australia any more</td>\n",
       "      <td>[jb, isnt, showing, in, australia, any, more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>ok thats it you win.</td>\n",
       "      <td>ok thats it you win</td>\n",
       "      <td>[ok, thats, it, you, win]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentiment                                      SentimentText  \\\n",
       "0           0                       is so sad for my APL frie...   \n",
       "1           0                     I missed the New Moon trail...   \n",
       "2           1                            omg its already 7:30 :O   \n",
       "3           0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4           0           i think mi bf is cheating on me!!!   ...   \n",
       "5           0                  or i just worry too much?           \n",
       "6           1                 Juuuuuuuuuuuuuuuuussssst Chillin!!   \n",
       "7           0         Sunny Again        Work Tomorrow  :-|  ...   \n",
       "8           1        handed in my uniform today . i miss you ...   \n",
       "9           1           hmmmm.... i wonder how she my number @-)   \n",
       "10          0                      I must think about positive..   \n",
       "11          1        thanks to all the haters up in my face a...   \n",
       "12          0                     this weekend has sucked so far   \n",
       "13          0             jb isnt showing in australia any more!   \n",
       "14          0                               ok thats it you win.   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "0                         is so sad for my apl friend   \n",
       "1                       i missed the new moon trailer   \n",
       "2                               omg its already 730 o   \n",
       "3              omgaga im sooo  im gunna cry ive be...   \n",
       "4            i think mi bf is cheating on me       tt   \n",
       "5                    or i just worry too much           \n",
       "6                    juuuuuuuuuuuuuuuuussssst chillin   \n",
       "7          sunny again        work tomorrow       ...   \n",
       "8         handed in my uniform today  i miss you a...   \n",
       "9                   hmmmm i wonder how she my number    \n",
       "10                        i must think about positive   \n",
       "11        thanks to all the haters up in my face a...   \n",
       "12                     this weekend has sucked so far   \n",
       "13              jb isnt showing in australia any more   \n",
       "14                                ok thats it you win   \n",
       "\n",
       "                                            tokenized  \n",
       "0                 [is, so, sad, for, my, apl, friend]  \n",
       "1                [i, missed, the, new, moon, trailer]  \n",
       "2                         [omg, its, already, 730, o]  \n",
       "3   [omgaga, im, sooo, im, gunna, cry, ive, been, ...  \n",
       "4        [i, think, mi, bf, is, cheating, on, me, tt]  \n",
       "5                     [or, i, just, worry, too, much]  \n",
       "6                 [juuuuuuuuuuuuuuuuussssst, chillin]  \n",
       "7         [sunny, again, work, tomorrow, tv, tonight]  \n",
       "8   [handed, in, my, uniform, today, i, miss, you,...  \n",
       "9            [hmmmm, i, wonder, how, she, my, number]  \n",
       "10                  [i, must, think, about, positive]  \n",
       "11  [thanks, to, all, the, haters, up, in, my, fac...  \n",
       "12              [this, weekend, has, sucked, so, far]  \n",
       "13      [jb, isnt, showing, in, australia, any, more]  \n",
       "14                          [ok, thats, it, you, win]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = text_cleaning(df_cleaned)\n",
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eaac9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tfidf_vect,X_train,X_test,y_train,y_test = text_features(df2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12beecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7593396743347808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = model.predict(tfidf_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a48d55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'This is crazy guys'\n",
    "text_pred_cleaning(txt, tfidf_vect, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83817e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2 = 'i hate all of you'\n",
    "text_pred_cleaning(txt2, tfidf_vect, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722bffc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt3 = 'I am happy with my life'\n",
    "text_pred_cleaning(txt3, tfidf_vect, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "421e3cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt4 = 'I am feeling depressed'\n",
    "text_pred_cleaning(txt4, tfidf_vect, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8423d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
